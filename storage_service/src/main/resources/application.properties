server.port=8080

logging.level.org.apache.kafka.clients.NetworkClient = ERROR
#logging.level.org.apache.kafka = ERROR

### Web request
spring.servlet.multipart.max-file-size=-1
spring.servlet.multipart.max-request-size=-1
    #for jetty 0 is intended as use memory unlimited (check is on > 0). So use 1 if you want only to use disk
spring.servlet.multipart.file-size-threshold=100000000
    #Default is 30 sec. Set to 2 min
spring.mvc.async.request-timeout=120000
#spring.mvc.async.request-timeout=3000


### Mongo
spring.data.mongodb.uri= mongodb://mongo1:30001,mongo2:30002,mongo3:30003/replicaSet=rset
#spring.data.mongodb.uri= mongodb://gabriele:test@localhost:27017/admin
spring.data.mongodb.database=test-database
spring.data.mongodb.gridfs.chunk-size-bytes = 261120
spring.data.mongodb.gridfs.bucket=rcs
spring.data.mongodb.write-concern.wtimeout-millis=10000
spring.data.mongodb.write-concern.journal=true

### Kafka
spring.kafka.consumer.max-poll-records=1000
spring.kafka.consumer.fetch-max-bytes=52428800
spring.kafka.consumer.max-partition-fetch-bytes=1048576
spring.kafka.concurrency-listener=10
spring.kafka.topics.number-of-partitions=10
spring.kafka.batchListener.enabled = false
spring.kafka.batchListener.aggregation = false

### Actuator
management.endpoint.chaosmonkey.enabled=true
management.endpoint.chaosmonkeyjmx.enabled=true
    # include specific endpoints
management.endpoints.web.exposure.include=health,info,chaosmonkey

### Chaos Monkey
spring.profiles.active=chaos-monkey
chaos.monkey.enabled=true
chaos.monkey.watcher.controller=false
chaos.monkey.watcher.restController=true
chaos.monkey.watcher.service=true
chaos.monkey.watcher.repository=true
chaos.monkey.watcher.component=false


### Application specific values
    #2MB
reading-block-size = 2097152
    #1MB
streaming-buffer-size = 1048576
collection.suffix=tonic
benchmarking=false
kind-of-transactionality=ADHOC

bulk-write=false

#Information needed to create csv file for benchmarking
number-of-generator-threads=50
sending-bytes-rate=1
